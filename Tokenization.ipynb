{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHU3nI4NHVR+RIyQhgyi+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yee030/Preprocessing/blob/main/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "1oVVFqTQ0HCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt') #punkt는 NLTK(Natural Language Toolkit) 라이브러리에서 사용되는 토큰화"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p62nQ5700I5D",
        "outputId": "24a66ec7-34d2-4421-b07a-29a3d26b8f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JFvcRlk80Ld8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "os7pUp9ty5YO"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize  #단어 토큰화\n",
        "from nltk.tokenize import WordPunctTokenizer #'도 분리\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화1 :',word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wRb3oYbzNq0",
        "outputId": "737bbf87-58ad-4691-8636-7cfee2847f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화1 : ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화1-1 :',word_tokenize(\"안녕하세요. 인공지능공학과 22학번 김영은입니다.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "-lER9kF-4XtW",
        "outputId": "a23909d6-2386-4b8c-b749-bd1211f9c971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-0c5c545e3a1e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print('단어 토큰화1-1 :',word_tokenize(\"안녕하세요. 인공지능공학과 22학번 김영은입니다.\")\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화2 :',WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi1uBPMW1Mad",
        "outputId": "cfe416a6-b348-4dfc-d0d9-9afc5ed46e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화2 : ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화3 :',text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FnaLOBD26JY",
        "outputId": "8c076bf3-8d0d-44b8-a086-f89cf8b011f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화3 : [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "\n",
        "text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
        "print('트리뱅크 워드토크나이저 :',tokenizer.tokenize(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXHhxqjm3Eyy",
        "outputId": "1ddc8df7-b40e-4274-b55b-7e522c6c9738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "트리뱅크 워드토크나이저 : ['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "text = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
        "print('문장 토큰화1 :',sent_tokenize(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUocg7UP3HV0",
        "outputId": "8752d733-59a6-4b29-8d33-246ceb2450e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 토큰화1 : ['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n",
        "print('문장 토큰화2 :',sent_tokenize(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOwMSU2X3n-D",
        "outputId": "c108ceb6-325c-4e6b-8a8a-fecc78133031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 토큰화2 : ['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kss # 한국어 토큰회\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wRQyCWH4Kcj",
        "outputId": "dbcb335a-ca28-4cec-bd02-869b968d9c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kss in /usr/local/lib/python3.10/dist-packages (4.5.4)\n",
            "Requirement already satisfied: emoji==1.2.0 in /usr/local/lib/python3.10/dist-packages (from kss) (1.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from kss) (2023.6.3)\n",
            "Requirement already satisfied: pecab in /usr/local/lib/python3.10/dist-packages (from kss) (1.0.8)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from kss) (3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (1.23.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (9.0.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (7.4.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kss\n",
        "\n",
        "text = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\n",
        "print('한국어 문장 토큰화 :',kss.split_sentences(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLIWBrsx4Isd",
        "outputId": "ede50c7d-6a7b-45fd-b143-3cd3b68c33b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Because there's no supported C++ morpheme analyzer, Kss will take pecab as a backend. :D\n",
            "For your information, Kss also supports mecab backend.\n",
            "We recommend you to install mecab or konlpy.tag.Mecab for faster execution of Kss.\n",
            "Please refer to following web sites for details:\n",
            "- mecab: https://github.com/hyunwoongko/python-mecab-kor\n",
            "- konlpy.tag.Mecab: https://konlpy.org/en/latest/api/konlpy.tag/#mecab-class\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국어 문장 토큰화 : ['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다.', '이제 해보면 알걸요?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger') #averaged_perceptron_tagger 리소스 다운 받기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAZUXGcA7axN",
        "outputId": "1bbebe76-e89e-429e-bbcc-a2675f2bd827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "text = \" I am activrly looking for ph.D. students.and you are a Ph.D, student.\"\n",
        "tokenized_sentence = word_tokenize(text)\n",
        "\n",
        "print('단어 토큰화 : ', tokenized_sentence)\n",
        "print ('품사 태킹 : ', pos_tag(tokenized_sentence))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmIEuic05c3S",
        "outputId": "b9033a9d-a0c0-4ccd-a951-03eee6d7b7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화 :  ['I', 'am', 'activrly', 'looking', 'for', 'ph.D.', 'students.and', 'you', 'are', 'a', 'Ph.D', ',', 'student', '.']\n",
            "품사 태킹 :  [('I', 'PRP'), ('am', 'VBP'), ('activrly', 'RB'), ('looking', 'VBG'), ('for', 'IN'), ('ph.D.', 'NN'), ('students.and', 'NN'), ('you', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('Ph.D', 'NNP'), (',', ','), ('student', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "okt = Okt()\n",
        "kkma = Kkkma()\n",
        "\n",
        "print('OKT 형태소 분석 : ', okt.morphs(\"인공지능개론, 정말 재미 있어요.\"))\n",
        "print('OKT 품사 태깅 : ', okt.morphs(\"인공지능개론, 정말 재미 있어요.\"))"
      ],
      "metadata": {
        "id": "ZjWttTCw7iAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}